# -*- coding: utf-8 -*-
"""CE807_Assignment_2310246.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-JLbJd46WnmAmrpNjA0TFZB3ELyMJXLp

#CE807 Text Analytics assignment
#Student ID: 2310246

###Installing all the required libraries
"""

!pip install transformers
!pip install tensorflow
!pip install scikeras
!pip install scikit-learn

"""###Importing all the required libraries"""

import pandas as pd
import numpy as np
import re
import os
import pickle
import string
from nltk.stem.wordnet import WordNetLemmatizer
from nltk.corpus import stopwords

import nltk
nltk.download('wordnet')

import matplotlib.pyplot as plt
import seaborn as sns
import sklearn

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import LinearSVC

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.pipeline import Pipeline

import statistics
from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, roc_curve, log_loss
from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report
from sklearn.model_selection import cross_val_score
from sklearn.metrics import fbeta_score
from statistics import mean
from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import ShuffleSplit
from sklearn.model_selection import learning_curve

from wordcloud import WordCloud
from collections import Counter

import tensorflow as tf
from tensorflow.keras.layers import Embedding
from tensorflow.keras.models import Sequential
from tensorflow.keras.preprocessing import text, sequence
from tensorflow.keras.layers import Dense, Dropout, Activation
from scikeras.wrappers import KerasClassifier
from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D

import seaborn as sns
import matplotlib.pyplot as plt
from wordcloud import WordCloud, STOPWORDS

print(tf.__version__)

#[1],[2]

"""###Setting random seed using my student id



"""

student_id = 2310246

#numpy seed
np.random.seed(student_id)

"""###Allowing the GDrive access and setting data and model paths"""

# Mount Google Drive
from google.colab import drive
drive.mount('/content/gdrive', force_remount=True)

GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = './CE807-24-SP/Assignment/'
GOOGLE_DRIVE_PATH = os.path.join('gdrive', 'MyDrive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)
print('List files: ', os.listdir(GOOGLE_DRIVE_PATH))

DATA_PATH = os.path.join(GOOGLE_DRIVE_PATH, 'data', '6') # Make sure to replace 0 with last digit of your student Regitration number
train_file = os.path.join(DATA_PATH, 'train.csv')
print('Train file: ', train_file)

val_file = os.path.join(DATA_PATH, 'valid.csv')
print('Validation file: ', val_file)

test_file = os.path.join(DATA_PATH, 'test.csv')
print('Test file: ', test_file)


MODEL_PATH = os.path.join(GOOGLE_DRIVE_PATH, 'model', str(student_id)) # Make sure to use your student Regitration number
MODEL_Gen_DIRECTORY = os.path.join(MODEL_PATH, 'Model_Gen') # Model Generative directory
print('Model Generative directory: ', MODEL_Gen_DIRECTORY)

MODEL_Gen_File = MODEL_Gen_DIRECTORY + '.zip'


MODEL_Dis_DIRECTORY = os.path.join(MODEL_PATH, 'Model_Dis') # Model Discriminative directory
print('Model Discriminative directory: ', MODEL_Dis_DIRECTORY)

MODEL_Dis_File = MODEL_Dis_DIRECTORY + '.zip'

"""###Performance evaluation

Function for evaluating performance metrics like Accuracy, Recall (macro), Precision (macro), F1 (macro) and Confusion Matrix
"""

def compute_performance(y_true, y_pred, threshold):

    Y_tox = y_true
    Y_pred_tox = (y_pred > threshold).astype(float)

    # Compute Accuracy
    accuracy = accuracy_score(Y_tox, Y_pred_tox)

    # Compute Precision (macro)
    precision_macro = precision_score(Y_tox, Y_pred_tox, average='macro')

    # Compute Recall (macro)
    recall_macro = recall_score(Y_tox, Y_pred_tox, average='macro')

    # Compute F1-score (macro)
    f1_macro = f1_score(Y_tox, Y_pred_tox, average='macro')

    # Compute Confusion Matrix
    conf_matrix = confusion_matrix(Y_tox, Y_pred_tox)

    print("Accuracy:", accuracy)
    print("Precision (macro):", precision_macro)
    print("Recall (macro):", recall_macro)
    print("F1-score (macro):", f1_macro)
    print("Confusion Matrix:")
    print(conf_matrix)

    ax= plt.subplot()
    sns.heatmap(conf_matrix, annot=True, ax = ax, cmap='Blues')

    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    print()
    print("Classification Report-")
    print(classification_report(Y_tox, Y_pred_tox, target_names=["non toxic", "toxic"]))

#[1]

"""###Saving model and output"""

def save_model(model,model_dir):
  # save the model to disk
  # Check if the Model directory exists

  # Note you might have to modify this based on your requirement

  if not os.path.exists(model_dir):
      # Create the directory if it doesn't exist
      os.makedirs(model_dir)
      print(f"Directory '{model_dir}' created successfully.")
  else:
      print(f"Directory '{model_dir}' already exists.")

  model_file = os.path.join(model_dir, 'model.sav')
  pickle.dump(model, open(model_file, 'wb'))

  print('Saved model to ', model_file)

  return model_file

def load_model(model_file):
    # load model from disk

    # Note you might have to modify this based on your requirement

    model = pickle.load(open(model_file, 'rb'))

    print('Loaded model from ', model_file)

    return model

"""###Download GDrive Link into a directory"""

import requests

def extract_file_id_from_url(url):
    # Extract the file ID from the URL
    file_id = None
    if 'drive.google.com' in url:
        file_id = url.split('/')[-2]
    elif 'https://docs.google.com' in url:
        file_id = url.split('/')[-1]

    return file_id

def download_file_from_drive(file_id, file_path):
    # Construct the download URL
    download_url = f"https://drive.google.com/uc?id={file_id}"

    # Download the file
    response = requests.get(download_url)
    if response.status_code == 200:
        with open(file_path, 'wb') as f:
            f.write(response.content)
        print("File downloaded successfully!",file_path)
    else:
        print("Failed to download the file.")

def download_zip_file_from_link(file_url,file_path):

  file_id = extract_file_id_from_url(file_url)
  if file_id:
      download_file_from_drive(file_id, file_path)
  else:
      print("Invalid Google Drive URL.")

"""###Zip and Unzip a GDrive File"""

import zipfile
import shutil
import os

# Function to zip a directory
def zip_directory(directory, zip_filename):
    with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:
        for root, dirs, files in os.walk(directory):
            for file in files:
                zipf.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), os.path.join(directory, '..')))
        print('Created a zip file',zip_filename)

# Function to unzip a zip file
def unzip_file(zip_filename, extract_dir):
    with zipfile.ZipFile(zip_filename, 'r') as zip_ref:
        zip_ref.extractall(extract_dir)
    print('Extracted a zip file to',extract_dir)

# Example usage:
# directory_to_zip = 'path/to/your/directory'
# zip_filename = 'output_zipfile.zip'

# # Zip the directory
# zip_directory(directory_to_zip, zip_filename)

# # Unzip the zip file
# extract_dir = 'path/to/extract'
# unzip_file(zip_filename, extract_dir)

"""###Getting sharable link of Zip file in Gdrive"""

!pip install -U -q PyDrive

from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials


def get_gdrive_link(file_path):
    # Authenticate and create PyDrive client
    auth.authenticate_user()
    gauth = GoogleAuth()
    gauth.credentials = GoogleCredentials.get_application_default()
    drive = GoogleDrive(gauth)

    # Find the file in Google Drive
    file_name = file_path.split('/')[-1]
    file_list = drive.ListFile({'q': f"title='{file_name}'"}).GetList()

    # Get the file ID and generate the shareable link
    if file_list:
        file_id = file_list[0]['id']
        gdrive_link = f"https://drive.google.com/file/d/{file_id}/view?usp=sharing"
        return gdrive_link
    else:
        return "File not found in Google Drive"

def get_shareable_link(url):

    file_id = extract_file_id_from_url(url)

    auth.authenticate_user()
    gauth = GoogleAuth()
    gauth.credentials = GoogleCredentials.get_application_default()
    drive = GoogleDrive(gauth)

    try:
        file_obj = drive.CreateFile({'id': file_id})
        file_obj.FetchMetadata()
        file_obj.InsertPermission({
            'type': 'anyone',
            'value': 'anyone',
            'role': 'reader'
        })

        # Get the shareable link
        return file_obj['alternateLink']
    except Exception as e:
        print("Error:", e)
        return None

# if __name__ == "__main__":
#     # Replace 'YOUR_FILE_ID' with the ID of the file you want to share
#     file_id = 'YOUR_FILE_ID'
#     shareable_link = get_shareable_link(file_id)
#     if shareable_link:
#         print("Shareable link:", shareable_link)
#     else:
#         print("Failed to generate shareable link.")

"""#Data reading"""

#reading train file
train_df = pd.read_csv(train_file)
train_df.head()

# look at the columns,total entries & data type
train_df.info()

# check unique values
train_df.nunique()

#reading validation file
val_df = pd.read_csv(val_file)
val_df.head()

# look at the columns,total entries & data type
val_df.info()

# check unique values
val_df.nunique()

#reading test file
test_df = pd.read_csv(test_file)
test_df.head()

# look at the columns,total entries & data type
test_df.info()

#Checking shape of data
print("Training data shape: ",train_df.shape)
print("Validation data shape: ",val_df.shape)
print("Testing data shape: ",test_df.shape)

#[1]

#Check for null values
null_train = train_df.isnull().sum()
print("Null values in training set: ")
print(null_train)
print()
null_val = val_df.isnull().sum()
print("Null values in testing set: ")
print(null_val)
print()
null_test = test_df.isnull().sum()
print("Null values in test label set: ")
print(null_test)

#[1]

"""#Data preprocessing

Tokenize text and return a non-unique list of tokenized words found in the text.
Normalize to lowercase, strip punctuation, remove stop words, filter non-ascii characters.
Lemmatize the words and lastly drop words of length < 3.
"""

def tokenize(text):
    text = text.lower()
    regex = re.compile('[' + re.escape(string.punctuation) + '0-9\\r\\t\\n]')
    nopunct = regex.sub(" ", text)
    words = nopunct.split(' ')
    # remove any non ascii
    words = [word.encode('ascii', 'ignore').decode('ascii') for word in words]
    lmtzr = WordNetLemmatizer()
    words = [lmtzr.lemmatize(w) for w in words]
    words = [w for w in words if len(w) > 2]
    return words

#[2]

# clean text
train_df['comment'] = train_df['comment'].apply(lambda x: tokenize(x))
val_df['comment'] = val_df['comment'].apply(lambda x: tokenize(x))
test_df['comment']  = test_df['comment'].apply(lambda x: tokenize(x))

#[2]

# look at train comments
x_train = train_df['comment'].apply(lambda x: ' '.join(x))
print(x_train)

# look at validation comments
x_val = val_df['comment'].apply(lambda x: ' '.join(x))
print(x_val)

"""#Data Visualization

The below plot shows the comment length frequency. As observed, most of the comments are short with only a few comments longer than 100 words.
"""

sns.set(color_codes=True)
comment_len = train_df.comment.str.len()
sns.distplot(comment_len, kde=False, bins=20, color="steelblue")

#[2]

"""Below is the plot for the labeled data frequency. There is significant class imbalance since majority of the comments are considered non-toxic."""

# Code to draw bar graph for visualising distribution of classes within each label.
barWidth = 0.25

bars1 = [sum(train_df['toxicity'] == 1)]
bars2 = [sum(train_df['toxicity'] == 0)]

r1 = np.arange(len(bars1))
r2 = [x + barWidth for x in r1]

plt.bar(r1, bars1, color='steelblue', width=barWidth, label='Toxic = 1')
plt.bar(r2, bars2, color='lightsteelblue', width=barWidth, label='Non Toxic = 0')

plt.xlabel('group', fontweight='bold')
plt.xticks([r + barWidth for r in range(len(bars1))], ['Non Toxic'])
plt.legend()
plt.show()

#[2]

"""Visualizing the most common words contributing to Toxicity"""

#plot the most frequent words in the dataset using word cloud
#font size is chosen by the frequency of the word in the data
def word_plot(column,text):

    comments = train_df[train_df['toxicity'] == 1]   # sort by toxicity

    word_cloud = WordCloud(width = 640, height = 640, background_color = 'black').generate(str(comments))

    fig = plt.figure( figsize = (8, 5), facecolor = 'k', edgecolor = 'k')
    plt.subplot()
    plt.imshow(word_cloud, interpolation = 'bilinear')
    plt.suptitle("Most frequent words in " +  text , y = 1.06,color = "white")
    plt.tight_layout(pad = 0)
    plt.axis('off')
    plt.show()

word_plot(train_df['toxicity'], "Toxic comments")

#[1]

"""Checking the distribution of Toxicity in Percentage in train set:
- 87% of toxicity labelled as 0. Only 13% of toxicity is labelled as 1. This means that the amount of toxic comment is very less which means there is a high imbalance of classes.
- Some undersampling or oversampling should be performed to remove imbalance.
"""

# Distribution of Toxicity in Percentage in train set
print("Distribution of Training Toxicity in Percentage:")
print()
print((train_df['toxicity'].value_counts()/8699)*100)
print()

#[1]

"""Checking the distribution of Toxicity in Percentage in validation set:
- 86.85% of toxicity labelled as 0. Only 13.15% of toxicity is labelled as 1. This means that the amount of toxic comment is very less which means there is a high imbalance of classes in validation set as well.
"""

# Distribution of Toxicity in Percentage in validation set
print("Distribution of Validation Toxicity in Percentage:")
print()
print((val_df['toxicity'].value_counts()/2920)*100)
print()

#[1]

#Check where training labels have a row with only zeros
zero_rows_y = np.where(train_df['toxicity'] == 0)[0]
zero_rows_y

#[1]

print("Rows with zeros in training labels: ",zero_rows_y.shape) #check shape
print("Shape of training labels          : ", train_df['toxicity'].shape)

#[1]

#calcualte percentage of rows with only zeros in toxicity label
7568 / 8699

"""- **7568** rows out of 8699 rows in training data do not have any label as 1.
Or in other words approx 87% of the comments are non toxic.
- There is a high chance of overfitting and getting a good accuracy with a model which predicts almost all comments as non toxic.
- The problem is to fit the data such that it also predicts the toxicity and the type of toxicity accurately.

#Under Sampling

- SMOTE(Synthetic Minority Oversampling Technique), RandomOverSampler and RandomUnderSampler are efficient techniques to perform oversampling or undersampling but it does not work well when there is a huge imbalance in the dataset and there are very few samples for a particular class. So these techniques do not fit well with this dataset.
- I will perform Under Sampling by dropping a few rows of data.
- I will drop 35% of comments which have labels as all zeros.
- I have chosen this number so that I do not decrease the dataset by a large amount and still have enough comments which are not toxic to train the model in an efficient manner.

[1]
"""

# Calculating 35% of labels with rows with only zeros
(7568*35)/100

# Get index where rows of training labels are zeros
drop_rows_indx = zero_rows_y[0:2600]
drop_rows_indx

#check the shape of rows dropped in train set
drop_rows_indx.shape

# Dropping the first 2600 rows of training data
for indx in drop_rows_indx:
    train_df = train_df.drop([indx], axis=0)

#checking the shape of train set after dropping rows
train_df.shape

#reading train set
train_df

"""Checking the distribution of Toxicity in Percentage in train set after under sampling:"""

print("Distribution of Training Classes in Percentage:")
print()
print((train_df['toxicity'].value_counts()/6099)*100)
print()

"""The distribution of toxicity is slightly more balanced than before with 81.5% non toxic data and 18.5% toxic data."""

#check null values
null_train = train_df.isnull().sum()
print("Null values in training : ")
print(null_train)
print()

# store training features in x
train_x = train_df['comment'].apply(lambda x: ' '.join(x))
print(train_x)

"""#Generative model - Multinomial Naive Bayes

Under generative method, I have used Multinomial Naive Bayes model for text classification.

###Feature extraction
- Vectorization performed by converting preprocessed text data into numerical features using a technique called Bag-of-Words (BoW).

###Training and evaluation of Naive Bayes model:
- Takes train_file, val_file and model_dir as input.
- It is trained on the train_file datapoints, and validate on the val_file datapoints.
- While training and validating, it prints different evaluataion metrics and losses, wherever necessary.
- After finishing the training, it saves the best model in the model_dir.
- Args:
 - train_file: Train file name
 - val_file: Validation file name
 - model_dir: Model output Directory
"""

def train_Gen(train_file, val_file, model_dir):

    # Model Declaration
    pipeline = Pipeline([
            ('vectorizer', CountVectorizer()),
            ('classifier', MultinomialNB()) ])

    # Model training
    pipeline.fit(train_x, train_df['toxicity'])

    # Test Model on Validation Data and Get F1 Score
    val_pred= pipeline.predict(x_val)

    # get the performance metrics
    performance = compute_performance(val_df['toxicity'], val_pred, 0.5)

    # Model is working fine, so save model
    save_model(pipeline, model_dir)

    # Now Zip Model to share it
    zip_directory(model_dir, MODEL_Gen_File)

    model_gdrive_link = get_gdrive_link(MODEL_Gen_File)

    print(model_gdrive_link)
    get_shareable_link(model_gdrive_link)

    return model_gdrive_link

model_gdrive_link = train_Gen(train_file, val_file, MODEL_Gen_DIRECTORY)

"""Here's a brief summary of the output results for the Naive Bayes model:

- Accuracy: The model achieves an accuracy of approximately 85.89%, indicating the overall correctness of predictions.
- Precision (macro): The average precision across both classes (toxic and non-toxic) is around 51.78%, suggesting a moderate ability to correctly identify positive and negative instances.
- Recall (macro): The average recall across both classes is approximately 50.22%, indicating the model's ability to recall instances from both classes.
- F1-score (macro): The harmonic mean of precision and recall across both classes is about 47.84%, indicating a balanced performance in terms of precision and recall.
- Confusion Matrix:
True Negative (TN): 2501
False Positive (FP): 35
False Negative (FN): 377
True Positive (TP): 7

Overall, the Naive Bayes model achieves a relatively high accuracy but struggles with correctly identifying toxic comments, as evidenced by the low recall and F1-score for the 'toxic' class. There is potential for improvement in correctly identifying toxic comments while maintaining high accuracy.

###Testing Naive Bayes model:
- Takes test_file and model_gdrive_link as input.
- It loads model and test of the examples in the test_file.
- It prints different evaluation metrics, and saves the output label in test_file.
- Args:
  - test_file: test file name
  - model_gdrive_link: Gdrive url
"""

def test_Gen(test_file, model_gdrive_link):

    # These two are temporary directory and file
    test_model_file = MODEL_PATH+'/test.zip'
    test_model_path = MODEL_PATH+'/test/'

    # Now download and unzip the model file
    download_zip_file_from_link(model_gdrive_link,test_model_file)
    print('Model downloaded to', test_model_file)
    unzip_file(test_model_file, test_model_path)
    print('\n Model is downloaded to ',test_model_path)

    # Let's get test data
    test_df = pd.read_csv(test_file)
    print('\n Data is loaded from ', test_file)

    # Let's get the model file name & load it
    test_model_file = os.path.join(test_model_path, 'Model_Gen', 'model.sav')
    model = load_model(test_model_file)

    # Let's do the prediction using test data
    y_pred= model.predict(test_df['comment'])

    # Now save the model output in the same test file
    test_df['out_label_model_Gen'] = y_pred

    # Now save the model output in the same output file
    test_df.to_csv(test_file, index=False)
    print('\n Output is save in ', test_file)

    return test_file

"""**Naive Bayes model results:**
In my test set, out_label_model_Gen column has generated values with:
- 73 instances generated as 1 (toxic).
- 2823 instances generated as 0 (non toxic).

###Performing hyperparameter tuning with Grid Search
Tuning hyperparameters of the Naive Bayes model using grid search technique:
"""

# Create an instance of the Naive Bayes classifier
naive_bayes_classifier = MultinomialNB()

# Define the grid of parameters to search over
parameter_grid = {'alpha': [0.1, 0.5, 1.0, 2.0],  # Smoothing parameter
                  'fit_prior': [True, False]}  # Whether to learn class prior probabilities or not

# Define the cross-validation strategy (Stratified K-Fold with 5 splits)
cross_validation = StratifiedKFold(n_splits=5)

# Set up the grid search using F1-score as the scoring metric
grid_search = GridSearchCV(naive_bayes_classifier,
                           param_grid=parameter_grid,  # Grid of parameters to search over
                           cv=cross_validation,  # Cross-validation strategy
                           scoring='f1')  # Scoring metric to optimize for

# Initializing the CountVectorizer to convert text data into numerical features
vectorizer = CountVectorizer()

# Transforming the training text data into a sparse matrix of token counts
x_train_transformed = vectorizer.fit_transform(train_x)

# Performing grid search to find the best parameters for the logistic regression model
grid_search.fit(x_train_transformed, train_df['toxicity'])

# Print the best parameters found by grid search
print('Best parameters: {}'.format(grid_search.best_params_))

# Return the best estimator (Naive Bayes model) found by grid search
grid_search.best_estimator_

#[2]

"""Taking best parameters from grid search and evaluating the Naive Bayes model:"""

def train_Gen(train_file, val_file, model_dir):

    # Model Declaration
    pipeline = Pipeline([
            ('vectorizer', CountVectorizer()),
            ('classifier', MultinomialNB(alpha=0.1, fit_prior=False)) ])

    # Model training
    pipeline.fit(train_x, train_df['toxicity'])

    # Test Model on Validation Data
    val_pred= pipeline.predict(x_val)

    # get the performance metrics
    performance = compute_performance(val_df['toxicity'], val_pred, 0.5)

    # Model is working fine, so save model
    save_model(pipeline, model_dir)

    # Now Zip Model to share it
    zip_directory(model_dir, MODEL_Gen_File)

    model_gdrive_link = get_gdrive_link(MODEL_Gen_File)

    print(model_gdrive_link)
    get_shareable_link(model_gdrive_link)

    return model_gdrive_link

model_gdrive_link = train_Gen(train_file, val_file, MODEL_Gen_DIRECTORY)

"""Here's a brief summary of the output results for the Naive Bayes model after hyperparameter tuning:

- Accuracy: The model achieves an accuracy of approximately 72.05%, indicating the overall correctness of predictions.
- Precision (macro): The average precision across both classes (toxic and non-toxic) is around 50.38%, suggesting a moderate ability to correctly identify positive and negative instances.
- Recall (macro): The average recall across both classes is approximately 50.54%, indicating the model's ability to recall instances from both classes.
- F1-score (macro): The harmonic mean of precision and recall across both classes is about 49.97%, indicating a balanced performance in terms of precision and recall.
- Confusion Matrix:
True Negative (TN): 2022
False Positive (FP): 514
False Negative (FN): 302
True Positive (TP): 82

Overall, the Naive Bayes model shows moderate performance in identifying toxic comments, with balanced precision, recall, and F1-score around 50%. However, there is still room for improvement, especially in correctly identifying toxic comments (class 'toxic').

### Testing Naive Bayes model after tuning
"""

model_gdrive_link = 'https://drive.google.com/file/d/1tLUUccstQC2W_eOeibDiTIZK6flUKxoD/view?usp=sharing'
test_Gen(test_file, model_gdrive_link)

"""**Naive Bayes model results after tuning:** In my test set, out_label_model_Gen column has generated values having:
- 619 instances generated as 1 (toxic).
- 2277 instances generated as 0 (non toxic).

From my observation, F1 score has a slight increase, the accuracy and other performance metrics has decreased after tuning the model but it is able to classify more number of comments as toxic after tuning.

#Discriminative model

###1. Logistic Regression

###Feature extraction
- Vectorization performed by converting preprocessed text data into numerical features using a technique called Bag-of-Words (BoW).

###Training and evaluation of the model
- Takes train_file, val_file and model_dir as input.
- It is trained on the train_file datapoints, and validate on the val_file datapoints.
- While training and validating, it prints different evaluataion metrics and losses, wheverever necessary.
- After finishing the training, it saves the best model in the model_dir.
- Args:
  - train_file: Train file name
  - val_file: Validation file name
  - model_dir: Model output Directory
"""

def train_dis(train_file, val_file, model_dir):

    # Model Declaration
    pipeline = Pipeline([
            ('vectorizer', CountVectorizer()),
            ('classifier', LogisticRegression(max_iter=1000)) ])

    # Model training
    pipeline.fit(train_x, train_df['toxicity'])

    # Test Model on Validation Data
    val_pred = pipeline.predict(x_val)

    # get the performance metrics
    performance = compute_performance(val_df['toxicity'], val_pred, 0.5)

    # Model is working fine, so save model
    save_model(pipeline, model_dir)

    # Now Zip Model to share it
    zip_directory(model_dir, MODEL_Dis_File)

    model_gdrive_link = get_gdrive_link(MODEL_Dis_File)

    print(model_gdrive_link)
    get_shareable_link(model_gdrive_link)

    return model_gdrive_link

model_gdrive_link = train_dis(train_file, val_file, MODEL_Dis_DIRECTORY)

"""Here's a brief summary of the output results for the Logistic Regression model:
- Accuracy: The model achieves an accuracy of approximately 82.19%, indicating the overall correctness of predictions.
- Precision (macro): The average precision across both classes (toxic and non-toxic) is around 51.34%, suggesting a moderate ability to correctly identify positive and negative instances.
- Recall (macro): The average recall across both classes is approximately 50.74%, indicating the model's ability to recall instances from both classes.
- F1-score (macro): The harmonic mean of precision and recall across both classes is about 50.38%, indicating a balanced performance in terms of precision and recall.
- Confusion Matrix:
True Negative (TN): 2369
False Positive (FP): 167
False Negative (FN): 353
True Positive (TP): 31

Overall, the model shows decent performance in identifying toxic comments, with balanced precision, recall, and F1-score around 50%. However, there is still room for improvement, especially in correctly identifying toxic comments (class 'toxic').

###Testing the logistic regression model
- Take test_file and model_gdrive_link as input.
- It loads model and test of the examples in the test_file.
- It prints different evaluation metrics, and saves the output in output directory.
- Args:
  - test_file: test file name
  - model_gdrive_link: GDrive URL
"""

def test_dis(test_file, model_gdrive_link):

    # These two are temporary directory and file
    test_model_file = MODEL_PATH+'/test.zip'
    test_model_path = MODEL_PATH+'/test/'

    # Now download and unzip the model file
    download_zip_file_from_link(model_gdrive_link, test_model_file)
    print('Model downloaded to', test_model_file)
    unzip_file(test_model_file, test_model_path)
    print('\n Model is downloaded to ',test_model_path)

    # Let's get test data
    test_df = pd.read_csv(test_file)
    print('\n Data is loaded from ', test_file)

    # Let's get the model file name & load it
    test_model_file = os.path.join(test_model_path, 'Model_Dis', 'model.sav')
    model = load_model(test_model_file)

    # Let's do the prediction using test data
    y_pred= model.predict(test_df['comment'])

    # Now save the model output in the same test file
    test_df['out_label_model_Dis'] = y_pred

    # Now save the model output in the same output file
    test_df.to_csv(test_file, index=False)
    print('\n Output is save in ', test_file)

    return test_file

"""**Logistic regression model results:** In my test set, out_label_model_Dis column has generated values with:
- 175 instances generated as 1 (toxic).
- 2721 instances generated as 0 (non toxic).

###Performing hyperparameter tuning with Grid Search
Tuning hyperparameters of the logistic regression model using grid search technique:
"""

# Creating an instance of the Logistic Regression classifier with maximum iterations set to 1000
logistic_regression_classifier = LogisticRegression(max_iter=1000)

# Defining the grid of parameters to search over
parameter_grid = {'solver': ['newton-cg', 'lbfgs', 'liblinear'],  # Different solvers for optimization
                  'class_weight': [None, 'balanced']}  # Different class weights to address class imbalance

# Defining the cross-validation strategy (Stratified K-Fold with 5 splits)
cross_validation = StratifiedKFold(n_splits=5)

# Setting up the grid search using F1-score as the scoring metric
grid_search = GridSearchCV(logistic_regression_classifier,
                           param_grid=parameter_grid,  # Grid of parameters to search over
                           cv=cross_validation,  # Cross-validation strategy
                           scoring='f1')  # Scoring metric to optimize for

# Initializing the CountVectorizer to convert text data into numerical features
vectorizer = CountVectorizer()

# Transforming the training text data into a sparse matrix of token counts
x_train_transformed = vectorizer.fit_transform(train_x)

# Performing grid search to find the best parameters for the logistic regression model
grid_search.fit(x_train_transformed, train_df['toxicity'])

# Printing the best parameters found by grid search
print('Best parameters: {}'.format(grid_search.best_params_))

# Returning the best estimator (Logistic Regression model) found by grid search
grid_search.best_estimator_

#[2]

"""Taking best parameters from grid search and evaluating the logistic regression model:"""

def train_dis(train_file, val_file, model_dir):

    # Model Declaration
    pipeline = Pipeline([
            ('vectorizer', CountVectorizer()),
            ('classifier', LogisticRegression(class_weight='balanced', max_iter=1000, solver='newton-cg')) ])

    # Model training
    pipeline.fit(train_x, train_df['toxicity'])

    # Test Model on Validation Data
    val_pred = pipeline.predict(x_val)

    # get the performance metrics
    performance = compute_performance(val_df['toxicity'], val_pred, 0.5)

    # Model is working fine, so save model
    save_model(pipeline, model_dir)

    # Now Zip Model to share it
    zip_directory(model_dir, MODEL_Dis_File)

    model_gdrive_link = get_gdrive_link(MODEL_Dis_File)

    print(model_gdrive_link)
    get_shareable_link(model_gdrive_link)

    return model_gdrive_link

model_gdrive_link = train_dis(train_file, val_file, MODEL_Dis_DIRECTORY)

"""Here's a brief summary of the output results for the Logistic Regression model after hyperparameter tuning:
- Accuracy: The model achieves an accuracy of approximately 72.64%, indicating the overall correctness of predictions.
- Precision (macro): The average precision across both classes (toxic and non-toxic) is around 49.67%, which means that the model's ability to correctly identify positive and negative instances is slightly imbalanced.
- Recall (macro): The average recall across both classes is approximately 49.55%, suggesting that the model can recall less than half of the positive instances and negative instances in the dataset.
- F1-score (macro): The harmonic mean of precision and recall across both classes is about 49.30%, indicating a slightly imbalanced performance in terms of precision and recall.
- Confusion Matrix:
True Negative (TN): 2051
False Positive (FP): 485
False Negative (FN): 314
True Positive (TP): 70

Overall, the model shows moderate performance in identifying toxic comments, with precision, recall, and F1-score around 50%. However, there is room for improvement, especially in correctly identifying toxic comments (class 'toxic').

### Testing the Logistic regression model after tuning

**Logistic regression model results after tuning:** In my test set, out_label_model_Dis column has generated values with:
- 587 instances generated as 1 (toxic).
- 2309 instances generated as 0 (non toxic).

From my observation, the accuracy and other performance metrics has lowered after tuning the model but it is able to classify more number of comments as toxic after tuning.

###2. SVM (Support Vector Machine)

###Feature extraction
- Vectorization performed by converting preprocessed text data into numerical features using a technique called Bag-of-Words (BoW).

###Training and evaluation of the model
- Takes train_file, val_file and model_dir as input.
- It is trained on the train_file datapoints, and validate on the val_file datapoints.
- While training and validating, it prints different evaluataion metrics and losses, wheverever necessary.
- After finishing the training, it saves the best model in the model_dir.
- Args:
  - train_file: Train file name
  - val_file: Validation file name
  - model_dir: Model output Directory
"""

def train_dis(train_file, val_file, model_dir):

    # Model Declaration
    pipeline = Pipeline([
            ('vectorizer', CountVectorizer(max_features=20000)),
            ('classifier', LinearSVC(max_iter=100000)) ])

    # Model training
    pipeline.fit(train_x, train_df['toxicity'])

    # Test Model on Validation Data
    val_pred= pipeline.predict(x_val)

    # Get the performance metrics
    performance = compute_performance(val_df['toxicity'], val_pred, 0.5)

    # Model is working fine, so save model
    save_model(pipeline, model_dir)

    # Now Zip Model to share it
    zip_directory(model_dir, MODEL_Dis_File)

    model_gdrive_link = get_gdrive_link(MODEL_Dis_File)

    print(model_gdrive_link)
    get_shareable_link(model_gdrive_link)

    return model_gdrive_link

model_gdrive_link = train_dis(train_file, val_file, MODEL_Dis_DIRECTORY)

"""Here's a brief summary of the output results for the SVM model:
- Accuracy: The model achieves an accuracy of approximately 75.17%, indicating the overall correctness of predictions.
- Precision (macro): The average precision across both classes (toxic and non-toxic) is around 50.39%, which means that the model's ability to correctly identify positive and negative instances is balanced.
- Recall (macro): The average recall across both classes is approximately 50.46%, suggesting that the model can recall about half of the positive instances and negative instances in the dataset.
- F1-score (macro): The harmonic mean of precision and recall across both classes is about 50.33%, indicating a balanced performance in terms of precision and recall.
- Confusion Matrix:
True Negative (TN): 2130
False Positive (FP): 406
False Negative (FN): 319
True Positive (TP): 65

Overall, the model shows modest performance in identifying toxic comments, with precision, recall, and F1-score around 50%. There is room for improvement, especially in correctly identifying toxic comments (class 'toxic').

###Testing SVM model

**SVM model results:** In my test set, out_label_model_Dis column has generated values with:
- 811 instances generated as 1 (toxic).
- 2085 instances generated as 0 (non toxic).

###Performing hyperparameter tuning with Grid Search
Tuning hyperparameters of the SVM model using grid search technique:
"""

# Defining the Linear Support Vector Classifier with a maximum number of iterations
svm_classifier = LinearSVC(max_iter=100000)

# Defining a grid of parameters to search over for hyperparameter tuning
parameter_grid = {'C': [1, 5, 10],  # Regularization parameter
                  'class_weight': [None, 'balanced'],  # Class weight options
                  'fit_intercept': [True, False],  # Whether to fit the intercept
                  'intercept_scaling': [1.0, 2.0, 3.0],  # Scaling factor for the intercept
                  'tol': [0.001, 0.01, 0.1]}  # Tolerance for stopping criteria

# Defining cross-validation strategy using Stratified K-Fold with 5 splits
cross_validation = StratifiedKFold(n_splits=5)

# Setting up GridSearchCV for hyperparameter tuning with F1-score as the optimization metric
grid_search = GridSearchCV(svm_classifier,
                           param_grid=parameter_grid,
                           cv=cross_validation,
                           scoring='f1')

# Initializing CountVectorizer for converting text data into numerical features
vectorizer = CountVectorizer(max_features=20000)

# Transforming the training text data into a sparse matrix of token counts using CountVectorizer
x_train_transformed = vectorizer.fit_transform(train_x)

# Performing grid search to find the best parameters for the linear SVM model
grid_search.fit(x_train_transformed, train_df['toxicity'])

# Printing the best parameters found by grid search
print('Best parameters: {}'.format(grid_search.best_params_))

# Returning the best estimator (Linear SVM model) found by grid search
grid_search.best_estimator_

#[2]

"""Taking best parameters from grid search and evaluating the logistic regression model: The parameters obtained from grid search did not yield good results. So, I tried using different parameters that turned out to give better results."""

def train_dis(train_file, val_file, model_dir):

    # Model Declaration
    pipeline = Pipeline([
            ('vectorizer', CountVectorizer(max_features=20000)),
            ('classifier', LinearSVC(max_iter=100000, C=5, class_weight='balanced', fit_intercept=False,
          intercept_scaling=2.0, tol=0.1)) ])

    # Model training
    pipeline.fit(train_x, train_df['toxicity'])

    # Test Model on Validation Data
    val_pred= pipeline.predict(x_val)

    # Get the performance metrics
    performance = compute_performance(val_df['toxicity'], val_pred, 0.5)

    # Model is working fine, so save model
    save_model(pipeline, model_dir)

    # Now Zip Model to share it
    zip_directory(model_dir, MODEL_Dis_File)

    model_gdrive_link = get_gdrive_link(MODEL_Dis_File)

    print(model_gdrive_link)
    get_shareable_link(model_gdrive_link)

    return model_gdrive_link

model_gdrive_link = train_dis(train_file, val_file, MODEL_Dis_DIRECTORY)

"""Here's a brief summary of the output results for the SVM model after hyperparameter tuning:

- Accuracy: The model achieves an accuracy of approximately 70.99%, indicating the overall correctness of predictions.
- Precision (macro): The average precision across both classes (toxic and non-toxic) is around 50.61%, which means that the model's ability to correctly identify positive and negative instances is balanced.
- Recall (macro): The average recall across both classes is approximately 50.93%, suggesting that the model can recall about half of the positive instances and negative instances in the dataset.
- F1-score (macro): The harmonic mean of precision and recall across both classes is about 50.04%, indicating a balanced performance in terms of precision and recall.
- Confusion Matrix:
True Negative (TN): 1982
False Positive (FP): 554
False Negative (FN): 293
True Positive (TP): 91

Overall, the model shows modest performance in identifying toxic comments, with precision, recall, and F1-score around 50%. Despite hyperparameter tuning, there is still room for improvement, especially in correctly identifying toxic comments (class 'toxic').

###Testing SVM model after tuning
"""

model_gdrive_link= 'https://drive.google.com/file/d/1-Ev5bTVXmIDE_N0w5IHc-RRwP_oX51Bu/view?usp=sharing'
test_dis(test_file, model_gdrive_link)

"""**SVM model results after tuning:** In my test set, out_label_model_Dis column has generated values with:
- 1005 instances generated as 1 (toxic).
- 1891 instances generated as 0 (non toxic).

From my observation, the accuracy and other performance metrics has lowered after tuning the model but it is able to classify more number of comments as toxic after tuning.

#Models comparison
Selecting 5 diverse interesting examples from the validation set with their ground truth/true label, and comparing it with both models (Naive Bayes and SVM) output.
"""

#Selecting 5 diverse examples from the validation set
examples = ["SDATA_6 :  NEWLINE_TOKENNEWLINE_TOKEN==PLEASE STOP IDIOT User: J Milburn,who is a picture deletor vandal!==  : EDATA_6",
            "SDATA_6 :  NEWLINE_TOKENWait, I've got it. Roger sings the lyrics to the chorus, so in this case, Rick is doing the backup. â€”   : EDATA_6",
            "SDATA_6 :   2007 (UTC)NEWLINE_TOKENNEWLINE_TOKEN:Your continued rudeness and failure to remotely discuss your controversial administrative actions just confirms for me that you are a terrible administrator.  Whatever I can do to get your administrative tools taken away from you, I will do.   20:25, 1 March  : EDATA_6",
            "SDATA_6 :  NEWLINE_TOKENNEWLINE_TOKENMy user page is now blank. Get over it. I called you a prick only after you had deleted the contents of my userpage and replaced them with a threatening message. Now stop threatening me or I will put one of those templates on your chat page. (  )  : EDATA_6",
            "SDATA_6 :  NEWLINE_TOKENNEWLINE_TOKEN== fuck you! ==NEWLINE_TOKENNEWLINE_TOKENhow dare you not rsvp me you bitch! i thought we had something, I'm the best thing you'll ever have.   : EDATA_6"]

#ground truth labels for the selected examples
ground_truth_labels = [1,1,0,0,1]

#Using Generative (Naive Bayes) model to predict labels for each example
# Model Declaration
pipeline = Pipeline([
    ('vectorizer', CountVectorizer()),
    ('classifier', MultinomialNB(alpha=0.1, fit_prior=False))
    ])

# Model training
pipeline.fit(train_x, train_df['toxicity'])

# Test Model on Validation Data examples
nb_pred = pipeline.predict(examples)
nb_pred

#Using Descriminative (SVM) model to predict labels for each example
# Model Declaration
pipeline = Pipeline([
        ('vectorizer', CountVectorizer(max_features=20000)),
        ('classifier', LinearSVC(max_iter=100000, C=5, class_weight='balanced', fit_intercept=False, intercept_scaling=2.0, tol=0.1))
        ])



# Model training
pipeline.fit(train_x, train_df['toxicity'])

# Test Model on Validation Data examples
svm_pred= pipeline.predict(examples)
svm_pred

#Comparing the predicted labels with ground truth labels for each model
for example, true_label, nb_p, svm_p in zip(examples, ground_truth_labels, nb_pred, svm_pred):
    print("Example:", example)
    print("True Label:", true_label)
    print("Naive Bayes Prediction:", nb_p)
    print("SVM Prediction:", svm_p)
    print()

"""Analyzing the predictions made by both the Naive Bayes and SVM models:

**Example 1**:
- True Label: 1 (Toxic)
- Naive Bayes Prediction: 0 (Non-toxic)
- SVM Prediction: 0 (Non-toxic)

Both models incorrectly predicted this example as non-toxic. It seems like the models failed to capture the toxicity of the content, possibly due to the context or nuances in the language used.

**Example 2**:
- True Label: 1 (Toxic)
- Naive Bayes Prediction: 0 (Non-toxic)
- SVM Prediction: 0 (Non-toxic)

Similar to Example 1, both models failed to identify the toxicity in this comment. It's possible that the language used is subtle or ambiguous, making it challenging for the models to detect toxicity.

**Example 3**:
- True Label: 0 (Non-toxic)
- Naive Bayes Prediction: 0 (Non-toxic)
- SVM Prediction: 0 (Non-toxic)

Both models correctly identified this example as non-toxic. The content seems to express frustration but does not contain explicitly toxic language.

**Example 4**:
- True Label: 0 (Non-toxic)
- Naive Bayes Prediction: 0 (Non-toxic)
- SVM Prediction: 1 (Toxic)

Naive Bayes correctly predicted this example as non-toxic, while the SVM model incorrectly classified it as toxic. The content may contain aggressive language, but it's subjective whether it qualifies as toxic or not.

**Example 5**:
- True Label: 1 (Toxic)
- Naive Bayes Prediction: 0 (Non-toxic)
- SVM Prediction: 1 (Toxic)

Naive Bayes incorrectly classified this example as non-toxic, whereas the SVM model correctly identified it as toxic. The language used is clearly aggressive and offensive, which the SVM model captured better.

**In terms of confidence**, both models seem to have low confidence in their predictions, as they often misclassify examples with clear toxicity (Examples 1, 2) and have mixed predictions for borderline cases (Examples 4, 5). This suggests that the models may require further tuning or additional features to improve their performance. Additionally, it's essential to analyze more examples and potentially incorporate context-aware features to enhance the model's understanding of toxic language.

#References
[1] Ankita Choudhury. Toxic-comment-classification, 2020.
https://github.com/ankita1112/Toxic-Comment-Classification

[2] Tianqi Wang. Toxic-Comment-Classification-Challenge, 2019.
https://github.com/tianqwang/Toxic-Comment-Classification-Challenge

# Other Method/model Start
"""

import argparse

# Define argparse-like function
def parse_arguments(option):
    parser = argparse.ArgumentParser(description='Process some integers.')
    parser.add_argument('--option', '-o',  type=str, default=option, help='Description of your option.')
    args = parser.parse_args(args=[])
    return args

# Function to perform some action based on selected option
def perform_action(option):
    print("Performing action with option:", option)

    if option == '0':
      print('\n Okay Exiting!!! ')

    elif option == '1':
      print('\n Training Generative Model')
      model_gdrive_link = train_Gen(train_file,val_file,MODEL_Gen_DIRECTORY)
      print('Make sure to pass model URL in Testing',model_gdrive_link)

    elif option == '2':
      print('\n\n Pass the URL Not Variable !!!')
      print('\n Testing Generative Model')
      model_gen_url = 'https://drive.google.com/file/d/1tLUUccstQC2W_eOeibDiTIZK6flUKxoD/view?usp=sharing'
      test_Gen(test_file, model_gen_url)

    elif option == '3':
      print('\n Training Disciminative Model')
      model_gdrive_link = train_dis(train_file,val_file,MODEL_Dis_DIRECTORY)
      print('Make sure to pass model URL in Testing',model_gdrive_link)
      print('\n\n Pass the URL Not Variable !!!')

    elif option == '4':
      print('\n\n Pass the URL Not Variable !!!')
      print('\n Testing Disciminative Model')
      model_dis_url = 'https://drive.google.com/file/d/1-Ev5bTVXmIDE_N0w5IHc-RRwP_oX51Bu/view?usp=sharing'
      test_dis(test_file, MODEL_PATH, model_dis_url)

    else:
      print('Wrong Option Selected. \n\nPlease select Correct option')
      main()


def main():

    # Get option from user input
    user_option = input("0. To Exit Code\n"
                     "1. Train Model Generative\n"
                    "2. Test Model Generative\n"
                    "3. Train Model Discriminative\n"
                    "4. Test Model Discriminative\n"
                    "Enter your option: ")

    args = parse_arguments(user_option)
    option = args.option
    perform_action(option)

main()